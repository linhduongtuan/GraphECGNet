{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wearable sensor dataset.\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from os.path import join\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torchaudio.transforms import Spectrogram\n",
    "\n",
    "import nlpaug.augmenter.spectrogram as nas\n",
    "import nlpaug.flow as naf\n",
    "\n",
    "import wfdb\n",
    "import ast\n",
    "#from src.datasets.root_paths import DATA_ROOTS\n",
    "DATA_ROOTS = '/users/mac/Downloads/ECG/PTB_XL/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DIAGNOSTIC_SUPERCLASS=['NORM','MI','STTC','CD','HYP']\n",
    "DIAGNOSTIC_SUBCLASS=['ISCA', 'LVH', 'IMI', 'CLBBB', 'LAO/LAE', 'AMI', 'LAFB/LPFB', 'RAO/RAE', 'ISCI', 'NST_', 'NORM', 'PMI', 'IRBBB', 'RVH', 'IVCD', 'LMI', 'CRBBB', 'STTC', '_AVB', 'ILBBB', 'WPW', 'ISC_', 'SEHYP']\n",
    "\n",
    "FEATURE_MEANS=np.array([-0.00074703,  0.00054328,  0.00128943,  0.0001024 , -0.00096791,\n",
    "        0.00094267,  0.0008255 , -0.00062468, -0.00335543, -0.00189922,\n",
    "        0.00095845,  0.000759  ])\n",
    "\n",
    "FEATURE_STDS=np.array([0.13347071, 0.19802795, 0.15897414, 0.14904783, 0.10836737,\n",
    "       0.16655428, 0.17850298, 0.33520913, 0.28028072, 0.27132468,\n",
    "       0.23750131, 0.19444742])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasePTB_XL(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode='train',\n",
    "        root=DATA_ROOTS, #['ptb_xl'],\n",
    "        measurements_per_example=1000,\n",
    "        examples_per_epoch=10000,\n",
    "        normalize=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.examples_per_epoch = examples_per_epoch\n",
    "        self.measurements_per_example = measurements_per_example  # Measurements used to make spectrogram\n",
    "        self.mode = mode\n",
    "        self.subject_data = self.load_data(root)\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def get_subject_ids(self, mode):\n",
    "        if mode == 'train':\n",
    "            nums = [1,2,3,4,5,6,7,8]\n",
    "        elif mode == 'train_small':\n",
    "            nums = [1]\n",
    "        elif mode == 'val':\n",
    "            nums = [9]\n",
    "        elif mode == 'test':\n",
    "            nums = [10]\n",
    "        else:\n",
    "            raise ValueError(f'mode must be one of [train, train_small, val, test]. got {mode}.')\n",
    "        return nums  \n",
    "\n",
    "    def load_data(self, root_path):\n",
    "        def load_raw_data(df, sampling_rate, path):\n",
    "            if sampling_rate == 100:\n",
    "                data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "            else:\n",
    "                data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "            data = np.array([signal for signal, meta in data])\n",
    "            return data\n",
    "\n",
    "        sampling_rate=100\n",
    "\n",
    "        # load and convert annotation data\n",
    "        print(\"load and convert annotation data\")\n",
    "        Y = pd.read_csv(root_path+'ptbxl_database.csv', index_col='ecg_id')\n",
    "        Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "        # Load raw signal data\n",
    "        print(\"Load raw signal data\")\n",
    "        X = load_raw_data(Y, sampling_rate, root_path)\n",
    "\n",
    "        # Load scp_statements.csv for diagnostic aggregation\n",
    "        print(\"Load scp_statements.csv for diagnostic aggregation\")\n",
    "        agg_df = pd.read_csv(root_path+'scp_statements.csv', index_col=0)\n",
    "        agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "        def aggregate_diagnostic(y_dic):\n",
    "            tmp = []\n",
    "            for key in y_dic.keys():\n",
    "                if key in agg_df.index:\n",
    "                    tmp.append(agg_df.loc[key].diagnostic_subclass)\n",
    "            conf=list(y_dic.values())\n",
    "            inds = []\n",
    "            seen = set()\n",
    "            for i, ele in enumerate(tmp):\n",
    "                if ele not in seen:\n",
    "                    inds.append((i))\n",
    "                seen.add(ele)\n",
    "            tmp1=[tmp[i] for i in inds]\n",
    "            conf1=[conf[i] for i in inds]\n",
    "            return  tmp1,conf1\n",
    "        Y['diagnostic_subclass'], Y['diagnostic_confidence'] = zip(*Y.scp_codes.apply(aggregate_diagnostic))\n",
    "\n",
    "        # Split data into train and test\n",
    "        test_fold = 10\n",
    "        # Train\n",
    "        X_train = X[np.where(Y.strat_fold != test_fold)]\n",
    "        #         print(\"X train shape:\", X_train.shape)\n",
    "        y_train = Y[(Y.strat_fold != test_fold)].diagnostic_subclass\n",
    "        #         print(\"y data\", y_train)\n",
    "        y_conf= Y[(Y.strat_fold != test_fold)].diagnostic_confidence.to_numpy()\n",
    "        y_train = y_train.to_numpy()\n",
    "        #         print(\"y train test\", y_train[0][0])\n",
    "        #         print(\"y train shape:\", y_train.shape)\n",
    "        #         print()\n",
    "        subject_data=[X_train,y_train,y_conf]\n",
    "        return subject_data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        while True:\n",
    "            ecgid = np.random.randint(len(self.subject_data[0]))\n",
    "            if len(self.subject_data[1][ecgid]) > 0: break\n",
    "                \n",
    "#         print(\"example diagnosis id\", self.subject_data[1][ecgid])\n",
    "        \n",
    "        max_conf=np.argmax(self.subject_data[2][ecgid])\n",
    "        diagnosis_id = DIAGNOSTIC_SUBCLASS.index(self.subject_data[1][ecgid][max_conf])\n",
    "        measurements = self.subject_data[0][ecgid]\n",
    "\n",
    "        # Yields spectrograms of shape [52, 32, 32]\n",
    "        spectrogram_transform=Spectrogram(n_fft=64-1, hop_length=32, power=2)\n",
    "        spectrogram = spectrogram_transform(torch.tensor(measurements.T))\n",
    "        spectrogram = (spectrogram + 1e-6).log()\n",
    "        if self.normalize:\n",
    "            spectrogram = (spectrogram - FEATURE_MEANS.reshape(-1, 1, 1)) / FEATURE_STDS.reshape(-1, 1, 1)\n",
    "#         print(\"spectrogram shape\", spectrogram.shape)\n",
    "#         print(\"diagnosis_id\", diagnosis_id)\n",
    "        return spectrogram, diagnosis_id\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.examples_per_epoch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrumAugmentation(object):\n",
    "\n",
    "    def __init__(self, just_time=False, noise=False):\n",
    "        super().__init__()\n",
    "        self.just_time = just_time\n",
    "        self.noise = noise\n",
    "\n",
    "    def get_random_freq_mask(self):\n",
    "        return nas.FrequencyMaskingAug(mask_factor=20)\n",
    "\n",
    "    def get_random_time_mask(self):\n",
    "        return nas.TimeMaskingAug(coverage=0.7)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        if self.just_time:\n",
    "            transforms = naf.Sequential([self.get_random_time_mask()])\n",
    "        else: \n",
    "            transforms = naf.Sequential([self.get_random_freq_mask(),\n",
    "                                     self.get_random_time_mask()])\n",
    "        data = transforms.augment(data)\n",
    "        if self.noise:\n",
    "            noise_stdev = 0.25 * np.array(FEATURE_STDS).reshape(1, 1, -1)\n",
    "            noise = np.random.normal(size=data.shape) * noise_stdev\n",
    "            data = data + noise\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTB_XL(data.Dataset):\n",
    "    NUM_CLASSES = 23  # NOTE: They're not contiguous labels.\n",
    "    NUM_CHANNELS = 12 # Multiple sensor readings from different parts of the body\n",
    "    FILTER_SIZE = 32\n",
    "    MULTI_LABEL = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode='train',\n",
    "        sensor_transforms= 'spectral_noise', #None,\n",
    "        root=DATA_ROOTS, #['ptb_xl'],\n",
    "        examples_per_epoch=10000  # Examples are generated stochastically.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.examples_per_epoch = examples_per_epoch\n",
    "        self.sensor_transforms = sensor_transforms\n",
    "        self.dataset = BasePTB_XL(\n",
    "            mode=mode, \n",
    "            root=root, \n",
    "            examples_per_epoch=examples_per_epoch)\n",
    "    \n",
    "    def transform(self, spectrogram):\n",
    "        if self.sensor_transforms:\n",
    "            if self.sensor_transforms == 'spectral':\n",
    "                spectral_transforms = SpectrumAugmentation()\n",
    "            elif self.sensor_transforms == 'spectral_noise':\n",
    "                spectral_transforms = SpectrumAugmentation(noise=True)\n",
    "            elif self.sensor_transforms == 'just_time':\n",
    "                spectral_transforms = SpectrumAugmentation(just_time=True)\n",
    "            else:\n",
    "                raise ValueError(f'Transforms {self.sensor_transforms} not implemented.')\n",
    "\n",
    "            spectrogram = spectrogram.numpy().transpose(1, 2, 0)\n",
    "            spectrogram = spectral_transforms(spectrogram)\n",
    "            spectrogram = torch.tensor(spectrogram.transpose(2, 0, 1))\n",
    "        elif self.sensor_transforms:\n",
    "            raise ValueError(\n",
    "                f'Transforms \"{self.sensor_transforms}\" not implemented.')\n",
    "        return spectrogram\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # pick random number\n",
    "        img_data, label = self.dataset.__getitem__(index)\n",
    "        subject_data = [\n",
    "            index,\n",
    "            self.transform(img_data).float(), \n",
    "            self.transform(img_data).float(),\n",
    "            label]\n",
    "\n",
    "        return tuple(subject_data)\n",
    "\n",
    "    \n",
    "    def imshow(img_data):\n",
    "        #img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img_data.numpy()\n",
    "        print(npimg)\n",
    "        #plt.imshow(np.transpose(npimg, (1, 2, 0, 1)))\n",
    "        plt.imshow(np.transpose(npimg[0].numpy(), (1, 2, 0)))\n",
    "        #plt.imshow(np.transpose(npimg[0].cpu().detach().numpy(), (1, 2, 0)))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.examples_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load and convert annotation data\n",
      "Load raw signal data\n",
      "Load scp_statements.csv for diagnostic aggregation\n"
     ]
    }
   ],
   "source": [
    "img = PTB_XL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'PTB_XL' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d20e9918ac5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#plt.imshow(np.transpose(npimg[0].cpu().detach().numpy(), (1, 2, 0)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-d20e9918ac5d>\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m     \u001b[0;31m# unnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnpimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#plt.imshow(np.transpose(npimg, (1, 2, 0, 1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'PTB_XL' and 'int'"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    print(npimg)\n",
    "    #plt.imshow(np.transpose(npimg, (1, 2, 0, 1)))\n",
    "    plt.imshow(np.transpose(npimg[0].numpy(), (1, 2, 0)))\n",
    "    #plt.imshow(np.transpose(npimg[0].cpu().detach().numpy(), (1, 2, 0)))\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fc8c611f46987eee559f675a23f9decc328b5f4b17b1da313eae285b0f1b6a2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
